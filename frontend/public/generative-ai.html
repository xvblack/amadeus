<html>
  <div>
    <span>Hello, everyone. I'm very excited for this conversation.</span>
    <span>I think this will be a lot of fun.</span>
    <span>The entire world is buzzing about generative AI these days.</span>
    <span>It's on the tip of everyone's tongue,</span>
    <span>and so it is a real privilege and a pleasure to have</span>
    <span>three true experts from the world of</span>
    <span>generative AI on stage with me here today representing</span>
    <span
      >three of the busiest and most exciting generative AI startups that
      are</span
    >
    <span
      >really helping to create and define these categories in real time.</span
    >
    <span>So I think it will be a great conversation.</span>
    <span>I'm Rob Taves. I'm a partner at Radical Ventures.</span>
    <span>We're a VC firm that's focused entirely on AI.</span>
    <span>I also write a regular column for</span>
    <span>Forbes about the big picture of artificial intelligence.</span>
    <span
      >Let me quickly introduce our three panelists and then we can dive
      in.</span
    >
    <span>So Chris Valenzuela, CEO, co-founder of</span>
    <span>Runway, which is a very exciting startup that's building</span>
    <span>a suite of AI-powered tooling for creatives,</span>
    <span
      >including a lot of tools around video editing and photo editing based New
      York City.</span
    >
    <span
      >I think something that I think is super exciting that maybe we'll get
      into more is,</span
    >
    <span
      >Runway just hosted the first ever AI film festival in New York City last
      week,</span
    >
    <span>which heralds a new age in the world of filmmaking.</span>
    <span>Next, we have Phil Blunsem, Chief Scientist of Cohere.</span>
    <span
      >Cohere is a company building cutting-edge large language models and
      making them</span
    >
    <span>available via API across industries,</span>
    <span>across use cases with the vision of democratizing access to</span>
    <span>the world's leading foundation models,</span>
    <span
      >language models to be used by 100 percent of the organizations around the
      world.</span
    >
    <span>Phil is also a professor of computer science at Oxford.</span>
    <span
      >Before joining Cohere, he was at DeepMind for seven years where he was a
      senior leader there,</span
    >
    <span
      >including founding and leading DeepMind's natural language research
      efforts.</span
    >
    <span
      >So he's a longtime veteran of the world of AI and generative AI and we're
      thrilled to have him here.</span
    >
    <span>Then last we have Dave, CEO and co-founder of Jasper,</span>
    <span>another super exciting generative AI startup.</span>
    <span>Jasper got founded in 2021,</span>
    <span
      >and by 2022, the company did $75 million in revenue according to
      TechCrunch,</span
    >
    <span
      >which makes it one of the fastest growing software companies in
      history,</span
    >
    <span>which is very impressive.</span>
    <span
      >In a nutshell, Jasper has built the world's leading AI-powered
      copywriting platform.</span
    >
    <span
      >So Jasper's platform can automatically generate all sorts of different
      content for users,</span
    >
    <span>including social media posts, blog posts,</span>
    <span>website copy, advertising copy,</span>
    <span>really, really neat and powerful tool.</span>
    <span
      >So with that said, there are plenty of big picture questions I'm excited
      to ask you guys</span
    >
    <span>about the world of AI,</span>
    <span
      >but maybe to start speaking about your respective specific
      companies.</span
    >
    <span
      >I would love to just hear a little bit about what each of the three you
      are working on,</span
    >
    <span>what the top priorities are for your organizations,</span>
    <span>and what you're most excited about in the year to come.</span>
    <span>Chris, we can start with you.</span>
    <span>Sure. We do a lot of different things on the runway,</span>
    <span>and we do it in a very integral, connected way.</span>
    <span
      >So for us, a lot of the things that we're working on are really making
      sure</span
    >
    <span
      >that we can keep pushing the boundaries of research in the space,</span
    >
    <span>specifically for customers,</span>
    <span
      >which tend to be filmmakers and artists and designers and creative at
      large,</span
    >
    <span>and so pushing the boundaries of research,</span>
    <span
      >but most importantly, making sure that that comes with a good product
      next to it.</span
    >
    <span
      >So we started the company like four years ago before the journey of the
      AI wave even begun,</span
    >
    <span
      >and so we build really that muscle of iterating a lot in both the
      research and the product side,</span
    >
    <span
      >and a lot of what we're doing now is just keeping that at a faster
      pace.</span
    >
    <span>Yeah, that's great.</span>
    <span>Phil, curious here more about Coher.</span>
    <span
      >Yeah, so my day-to-day is mostly focused on building and training the
      big-generative models,</span
    >
    <span
      >so we're really focused on just being in this flywheel of constantly
      making the models better every week,</span
    >
    <span
      >and one of our big focus at the moment is making these models
      enterprise-ready, enterprise-grade,</span
    >
    <span>because we've seen a lot of the promise of these models,</span>
    <span
      >but overcoming some of the rough edges and problems with these
      models.</span
    >
    <span
      >So yeah, it's very exciting, very fast-moving new developments and new
      features by the week.</span
    >
    <span>Dave?</span>
    <span
      >Yeah, for us, I mean, we're really trying to take this exciting, complex
      technology,</span
    >
    <span
      >simplify it, and build great UI, UX on top of it for businesses to go and
      create great content for their users to read and consume,</span
    >
    <span
      >and so this year a big focus is just really building out the platform
      more for like mid-market enterprises,</span
    >
    <span
      >building tooling to allow people to collaborate and just bring your
      entire team on there,</span
    >
    <span
      >helping to train these models to know the tone of voice of the
      company,</span
    >
    <span
      >to be able to retrieve facts accurately about the company and work those
      into the content,</span
    >
    <span
      >and then also right now we're primarily a web app that you go and you log
      in, you generate your content, copy and paste it back out.</span
    >
    <span
      >I really think the ideal workflow for users is that they're just jaspers
      already where you already are,</span
    >
    <span
      >so we're trying to take Jasper kind of outside of the app into all the
      other tooling that you're already using,</span
    >
    <span
      >and I really think that'll probably be like the primary way people use
      Jasper in the future,</span
    >
    <span
      >and then you'll go into the app for primary interfaces, and so, yeah,
      that's what we're doing this year.</span
    >
    <span
      >That's great, that's really exciting, and so maybe Chris, first big
      picture question I'm here,</span
    >
    <span
      >I'm curious here, all three of your perspectives on, there is obviously
      so much excitement and buzz around the world of generative AI.</span
    >
    <span
      >What is one thing that you think is really important or something that
      you believe strongly about generative AI</span
    >
    <span
      >that you think most people still don't understand or don't get
      right?</span
    >
    <span
      >I think there's this impression that there was a breakthrough moment a
      couple of months ago and things have really started to accelerate.</span
    >
    <span
      >The truth is that the research has been growing for like years and
      decades,</span
    >
    <span
      >and what we've seen more recently has been a more mainstream adoption of
      models and techniques and systems that have taken a lot of years to
      build.</span
    >
    <span
      >And with that in mind, I think one of the key things to keep in mind, and
      we do this a lot in runway as we think about product and research
      is,</span
    >
    <span
      >that it's still very early, like it's still a lot of, there's a lot of
      things that need to be built that haven't yet been built.</span
    >
    <span
      >I think we're transitioning from like pure research to engineering
      problems now,</span
    >
    <span
      >and it's about scaling and it's about optimizing the models and making
      them robust and controllable and more flexible.</span
    >
    <span
      >And so I think a good mental model to have is not to obsess about one
      specific model or one specific moment in time</span
    >
    <span
      >and focus more about the kind of like trajectory of where we are and
      where we're going to be in like the next couple of years.</span
    >
    <span
      >I think that helps better understand if you're really focused on building
      products and focusing on making sure that you keep on understanding the
      space</span
    >
    <span
      >and not really under optimizing for the wrong moment on the wrong
      thing.</span
    >
    <span
      >Yeah, I think it's a really important point and it is kind of
      collectively people look back at this moment, three or six months
      ago.</span
    >
    <span
      >I mean, chat GPT is obviously one major watershed that's caught a lot of
      people's attention,</span
    >
    <span
      >but it's worth noting that like all of the folks at OpenAI were shocked
      and surprised that chat GPT went so viral the way that it did,</span
    >
    <span
      >because the model that underlay that product had been available,</span
    >
    <span
      >freely available to the public via their playground for over a year to
      your point that like these models have existed,</span
    >
    <span>they've kind of been humanly building on one another.</span>
    <span
      >And so it's an interesting moment that I think a lot of people didn't
      necessarily see coming,</span
    >
    <span>but now being able to adapt to it nimbly is so important.</span>
    <span
      >Phil, I'm curious to hear your take that you think most people don't
      understand about it.</span
    >
    <span
      >Well, I thought that was a great answer and having worked on language
      modeling for, I guess, 20 years now.</span
    >
    <span>For most of that time, absolutely no one was interested in it.</span>
    <span
      >And then suddenly you open the sort of newspaper and you have language
      models on the front page of the newspaper.</span
    >
    <span
      >I'm not sure I could one concise answer, but there's a few answers.</span
    >
    <span>One is production doesn't equal comprehension,</span>
    <span
      >which is what we see with these models is they learn to produce
      convincing images or language before they learn to understand them,</span
    >
    <span>which is a reverse of what humans do.</span>
    <span>Children learn to understand before they learn to talk.</span>
    <span
      >So that's a big one that these things happen backwards, so that's going
      to be confusing to people.</span
    >
    <span
      >They see convincing outputs and think they must be understanding.</span
    >
    <span
      >But for instance, in image processing, we've made very little progress in
      terms of actual image understanding,</span
    >
    <span
      >being at a segment and things, but we can generate beautiful
      images.</span
    >
    <span>The other one I'd say is scale.</span>
    <span
      >I think people misunderstand scale a lot and they focus a lot on
      parameters.</span
    >
    <span
      >That's the wrong way to look at these models and definitely in the last
      few months,</span
    >
    <span
      >we've seen, if anything, or maybe the last six months, we're going
      backwards in scale models getting smaller in terms of number of
      parameters.</span
    >
    <span
      >But in other dimensions, they're getting bigger in terms of the amount of
      data we're training them on and things like this.</span
    >
    <span
      >So things like scale are a multi-dimensional aspect of these
      models.</span
    >
    <span>So there's a lot more going on than just parameters.</span>
    <span>Yeah, that's such an important point.</span>
  </div>
  <div>
    <span
      >And you and your team at DeepMind, the work that you guys did around
      Chinchilla last year,</span
    >
    <span
      >I think was such an important and groundbreaking piece of research in
      demonstrating that it really is not,</span
    >
    <span
      >what matters so much more than the number of parameters at least
      currently is the size of the training data set.</span
    >
    <span>And I think that's a nuance that a lot of people miss often.</span>
    <span>Dave, curious here, your contrarian take on generative AI.</span>
    <span
      >Yeah, I think the question that I probably get asked the most is just how
      did Jasper do it?</span
    >
    <span
      >And I think underlying that question is people thinking, well, you used
      another company's API to start and everybody had this thing.</span
    >
    <span>So what's really there?</span>
    <span
      >Like, is there even anything else to do that adds value to the
      customer?</span
    >
    <span
      >And I think what I keep coming back to is that I see a lot of people
      missing is that businesses always start with the customer and the
      need.</span
    >
    <span>And you work backwards from there.</span>
    <span
      >And that's what we've always really tried to do is that I'm a marketer by
      trade.</span
    >
    <span>I've been doing this for a long time.</span>
    <span
      >And I wasn't building large language models like Phil for 20 years.</span
    >
    <span>I was writing content and blog posts and ads and all of that.</span>
    <span>And so I was my own customer.</span>
    <span
      >And then I looked up and I see two years ago, hey, this is actually
      really good at writing the content I'm already writing.</span
    >
    <span>I was able to kind of connect those two.</span>
    <span>But it's always started with the customer and worked out.</span>
    <span
      >And what I see a lot of people now doing is starting at the technology
      and then just kind of trying to ram it into certain verticals or spaces or
      whatever,</span
    >
    <span>which is kind of what we did with Web 3.</span>
    <span
      >And it was like, we never really knew what it did, but it was really
      cool.</span
    >
    <span
      >And it sounded like it should work, but it was never like solving really
      tangible problems.</span
    >
    <span
      >And I just think people would be more successful when they build if they
      perhaps cared less about the technology itself and just more.</span
    >
    <span
      >We're talking to customers and really getting insights and then turning
      around and applying the proper technology at the right time in the right
      place for those customers.</span
    >
    <span>And so businesses have always been built that way.</span>
    <span
      >Technology is cool, but it'll always be about solving customer
      problems.</span
    >
    <span>And I think people should focus more there.</span>
    <span>Yeah, that's such a great point.</span>
    <span>I think all three of these companies do a great job of this.</span>
    <span
      >But someone put it to me very simply recently, which I thought was really
      insightful,</span
    >
    <span
      >which was that the secret that no one wants to admit about how to build a
      great AI company is to build a great company.</span
    >
    <span
      >And all the same things that you have to do still apply in terms of
      staying close to the customers you're saying and identifying a need that
      people are really willing to pay for.</span
    >
    <span>So I think that's a great point.</span>
    <span>And certainly something Jasper has done a great job of.</span>
    <span>Okay, this next question, I want to start with Phil.</span>
    <span>I'm curious to hear your thoughts on it.</span>
    <span
      >There have there's been a lot of discussion and debate around and kind of
      different pontification around in this gender to AI boom.</span
    >
    <span>Where will the value actually crew?</span>
    <span
      >Whereas especially a lot of the folks in the audience are
      investors.</span
    >
    <span
      >Where is the best place to deploy capital and which types of companies
      are going to end up being really durable and valuable and important over
      the long run?</span
    >
    <span
      >And I think an important subset of that question is the question of
      whether at the end of the day, the models themselves, the foundational
      models,</span
    >
    <span
      >the organizations like Cohere or Open AI or other companies are building,
      whether those models will become commodities over time or whether they
      will represent a durable source of defensibility.</span
    >
    <span>I'm curious to hear your take, Phil.</span>
    <span>Yeah, it's definitely an interesting question.</span>
    <span
      >One, I think there's a lot of value to go around, so it won't all be in
      one place.</span
    >
    <span
      >But definitely in from the view from Cohere, we think there's a lot of
      value in building the models.</span
    >
    <span>We don't think they'll become commodities and the model itself.</span>
    <span
      >And that's partly because that's not necessarily the thing that is this
      hard.</span
    >
    <span>Essentially, it's the thing you see.</span>
    <span
      >But we still think of big language models as big sort of one big
      artifact, the language model that's being trained.</span
    >
    <span>But that's not really what's happening now.</span>
    <span
      >It's better to look at it as a whole sort of stack of models and
      different training procedures.</span
    >
    <span
      >So we have big base language models that take huge amounts of computation
      to train, huge amounts of data.</span
    >
    <span>That data is cheap.</span>
    <span>We scraped it from the web, so maybe a trillion tokens.</span>
  </div>
  <div>
    <span
      >But on top of that, we have supervised reinforcement-learned
      models.</span
    >
    <span>They're much more computational efficient.</span>
    <span
      >We can train our model in a day, so we train it every week on new
      data.</span
    >
    <span>That data is much smaller.</span>
    <span>It's much more expensive.</span>
    <span>We have to actually go to human annotators to get that data.</span>
    <span
      >On top of that, that's where your conversational models come in, chat
      GPT.</span
    >
    <span
      >And then on top of those, we're seeing the integration with things like
      retrieval,</span
    >
    <span>both in terms of web search, enterprise search.</span>
    <span
      >And there's a whole other layer on there that hasn't really sort of made
      it into the public imagination yet.</span
    >
    <span
      >But what we think of is the action layer, and that's where these models
      actually act in the world.</span
    >
    <span>But that's a big, complicated stack.</span>
    <span>It's not something that's easy to reproduce.</span>
    <span>We're training these models constantly.</span>
    <span
      >It's not like one-shot, you train a model, you throw it out there, and
      everyone can use it forever.</span
    >
    <span>And we've seen that with the open-source models.</span>
    <span>They go stale quickly.</span>
    <span
      >So I think that the value there is really in the bringing together not
      just the computation,</span
    >
    <span
      >but the team, the capital, obviously, to fund it and to know how to keep
      it going</span
    >
    <span>sort of week after week to keep training.</span>
    <span
      >And there's a sort of, I think, a pretty good analogy for these big
      models,</span
    >
    <span>which is to look back a couple of decades to search.</span>
    <span>And search, of course, is all about having a web index,</span>
    <span
      >which you can, there's a pretty good analogy there for big language
      models.</span
    >
    <span>And we haven't seen those commoditized.</span>
    <span>We've actually seen the opposite.</span>
    <span>We've ended up with very few in the Western world.</span>
    <span>There are very few state-of-the-art web indices.</span>
    <span>So there's a similar thing there.</span>
    <span
      >And it's easy to describe to an engineer how to build a web index,</span
    >
    <span>but you don't see everyone going and doing it.</span>
    <span
      >It requires a lot of capital, a lot of computation, a lot of
      know-how,</span
    >
    <span>and you've got to keep doing it, otherwise it goes stale.</span>
    <span>Yeah, I think that's a really great analogy.</span>
    <span>At this point, people know how to build a web index,</span>
    <span>but it's not rational for hundreds of different companies</span>
    <span
      >to build their own indexes of the web and provide search engines.</span
    >
    <span
      >Dale, I'm curious, your take on this question, your perspectives,</span
    >
    <span>will the model layer commoditize over time?</span>
    <span
      >Well, since I'm with a bunch of investors, I have to say the application
      layers</span
    >
    <span>for all the value accrues.</span>
    <span>And I think it all commoditizes over time.</span>
    <span>I don't know if anything.</span>
    <span
      >We kind of just plant through a flag right now and stop innovating,</span
    >
    <span>would last a real long time.</span>
    <span>I agree with what Bill said.</span>
    <span>It's the continuation.</span>
    <span
      >It's the internal knowledge and ability to build something great</span
    >
    <span>and then continually iterate on that and continually advancing</span>
    <span>the ball downfield there is where there's a lot of value.</span>
    <span
      >I think at the end of the day, all of this tacked the applications,</span
    >
    <span
      >the models, again, the hardware seems to be really, really hard.</span
    >
    <span>I was with Andrew, the CEO, Cerebrus a couple of weeks ago,</span>
  </div>
  <br />
  <div>
    <span
      >and he was just like, felt like he'd been slogging it out for a
      decade.</span
    >
    <span>And I feel like he's probably the safest.</span>
    <span
      >But yeah, I think it's like going back to maybe my original
      thought,</span
    >
    <span>like the customer relationship is where there's a ton of value</span>
    <span
      >and being really close to the customer and building the kind of
      company</span
    >
    <span>that can continually see needs, solve needs,</span>
    <span
      >and do that in a really rapid way over and over is a tremendously
      valuable thing.</span
    >
    <span
      >And so for us, I don't really think of us as an application layer
      business.</span
    >
    <span>Obviously, that's kind of where we fit right now,</span>
    <span
      >but really in the business of solving whatever problems our customers
      have.</span
    >
    <span
      >And sometimes that might mean that we'll dip down into model layer</span
    >
    <span>and kind of across the stack if that's what it means.</span>
    <span>But I certainly think, like you said, too, Bill,</span>
    <span>there's like so much value everywhere</span>
    <span>that there's probably a lot of great companies to build here.</span>
    <span>Yeah, absolutely.</span>
    <span>Chris, I'm curious here.</span>
    <span>You mentioned that you started runway four or five years ago</span>
    <span>long before the current generative AI boom.</span>
    <span
      >And all three of you have been working in the space for a long
      time.</span
    >
    <span>What is a trend or a theme in the world of AI</span>
    <span>that you're excited about for the next three to five years</span>
    <span
      >that maybe everyone is not really excited about and talking about
      now,</span
    >
    <span
      >but you think will be super relevant and important going forward?</span
    >
    <span>I think a lot of people tend to think about models and research</span>
    <span>in a zero-sum kind of way, where the models do everything</span>
    <span>or they don't do nothing at all.</span>
    <span
      >I think a lot of the value will come from control and expression</span
    >
    <span>and making sure the models are robust and aligned</span>
    <span>to what you're trying to do and work in the way.</span>
    <span>So a lot of the work that I think what we're doing</span>
    <span>and some other folks are also doing</span>
    <span>is making sure the models are manageable and expressible</span>
    <span
      >and controllable in the ways that users or your intention tries to do
      it.</span
    >
    <span>And I think a lot of it doesn't come from making larger models</span>
    <span>or better models.</span>
    <span>It's just like the iteration component of UAX or UI sometimes.</span>
    <span
      >And iterating on how that gets deployed requires a lot of
      tinkering.</span
    >
    <span>I think toys really matter.</span>
    <span>Sometimes a toy gets dismissed as a toy</span>
    <span>because it might not look like something right now,</span>
    <span>but there's a lot of learning in that toy.</span>
    <span>And so I think I agree with what we just said,</span>
    <span>but a lot of what needs to be built is still ahead of us</span>
    <span>and that requires constant learning and building.</span>
    <span>And so, again, going back to, I guess, the first question,</span>
    <span>but we're still very early and there's a lot yet to uncover.</span>
    <span
      >So it's more of a mentality and a muscle to have and to cultivate</span
    >
    <span
      >to really truly understand everything that can be unpacked from
      this.</span
    >
    <span>Yep, yep.</span>
    <span
      >Kind of to that point around how early we are in the mega cycle.</span
    >
    <span
      >I'm curious to hear your all thoughts on how much actual adoption</span
    >
    <span>of next generation generative AI technology you're seeing</span>
    <span>within enterprises like Fortune 500, Main Street type companies</span>
    <span
      >and what the key blockers are that you think need to be resolved</span
    >
    <span
      >or need to be addressed before the floodgates can more fully open
      up.</span
    >
    <span>And Dave, maybe let's start with you.</span>
    <span
      >Yeah, I've been trying to sell to larger companies for two years
      now</span
    >
    <span
      >and a lot of the early adopters were all individuals and prosumers</span
    >
  </div>
  <br />
  <div>
    <span>and consumers using it and larger companies would not feel safe</span>
    <span>kind of bringing this in-house and using it.</span>
    <span>And what if it says something that we don't agree with,</span>
    <span>you know, like it was not a safe thing.</span>
    <span
      >And even just in the last six months, we've seen that like totally
      change</span
    >
    <span>where you might have gotten fired six months ago for using this</span>
    <span>and the company and now you're going to get fired if you don't.</span>
    <span>And like just the whole mindset around it has shifted</span>
    <span>where everyone's trying to figure out how do we do this?</span>
    <span>You know, how do we bring this in?</span>
    <span>How do we use it on our teams?</span>
    <span>How do we use it on our marketing teams?</span>
    <span>We've got to keep up.</span>
    <span>I think things that we're hearing a lot to do with care about</span>
    <span>obviously is, you know, these models hallucinate</span>
    <span>and they say things that are just not true.</span>
    <span>And in some industries or use cases, that's okay.</span>
    <span
      >You know, right in the blog post about your lawn mowing business,</span
    >
    <span>you know, it's probably okay if like you accidentally said</span>
    <span>the wrong type of grass.</span>
    <span>But if it's medical diagnoses, like that's obviously not okay.</span>
    <span>And so I think you're seeing people kind of weigh the costs</span>
    <span>and trade-offs of that.</span>
    <span>Like is it, how do we fact-check it?</span>
    <span>How do we make sure that it's saying what we want to say?</span>
    <span>And then how come probably with some of those, you know,</span>
    <span>kind of untrue statements that come out?</span>
    <span>I think, like I said too, what they're wanting is they want</span>
    <span>it built and to speak like them and to talk like them</span>
    <span>and to know what the knowledge base of the company is</span>
    <span>in order to like really roll this out.</span>
    <span>And I think security, you know, people have their own</span>
    <span>proprietary data and they want to keep that.</span>
    <span>And they see that as an asset in the company</span>
    <span>and I think it is and they don't want to let everybody else,</span>
    <span>you know, kind of use their own, use their data.</span>
    <span>And so they're really curious, you know,</span>
    <span>is there a way to kind of firewall this away</span>
    <span>from everything else and to maybe keep it on premise</span>
    <span>and, you know, lock that data down.</span>
    <span>And there's ways to do that.</span>
    <span>That's certainly some of the concerns that we're hearing.</span>
    <span>Yeah, yeah.</span>
    <span>And you mentioned hallucinations.</span>
    <span>So I want to pick up on that.</span>
    <span>And for folks in the audience that aren't familiar,</span>
    <span>the term basically just refers to language models,</span>
    <span>tendency to sometimes produce content that is false</span>
    <span>or made up or nonsensical.</span>
    <span>And it's a persistently difficult problem to solve</span>
    <span>with these language models.</span>
    <span>Phil, I'm curious to hear your perspective on this,</span>
    <span>because I think this is a really interesting question</span>
    <span>that no one really knows the answer to,</span>
    <span>but maybe isn't getting enough discussion yet,</span>
    <span>which is this challenge of hallucination</span>
    <span>for large language models.</span>
    <span>Is it something that you think we will,</span>
    <span>collectively, will be able to address</span>
    <span>through incremental tweaks and adjustments</span>
    <span>to the models as we're building them today?</span>
    <span>Or do you think it's possible that a more fundamental</span>
    <span>architectural or paradigm shift will be necessary</span>
    <span>in order to build models that have true,</span>
  </div>
  <div>
    <span>persistent common sense and true understanding</span>
    <span>of the world?</span>
    <span>Yeah, it's a great question.</span>
    <span>And I think there are sort of two parts.</span>
    <span>What we have today, we can do a lot more with.</span>
    <span>That's true, but at the same time,</span>
    <span>we haven't solved ALI in any sense.</span>
    <span>The sort of, what we're doing in industry</span>
    <span>has lagged research quite significantly.</span>
    <span>So research has run ahead quite a way</span>
    <span>in terms of what has been done</span>
    <span>compared to what has actually been deployed.</span>
    <span>And that's partly why, what is it now,</span>
    <span>about a year or more ago,</span>
    <span>there was actually quite a big exodus</span>
    <span>from a lot of these research labs,</span>
    <span>like Deep Mind where I was and Google Brain and others,</span>
    <span>because people are quite excited about the things</span>
    <span>they've done in research, but weren't being deployed.</span>
    <span>So there's a lot of research out there to address these.</span>
    <span>So we know that there's a good pipeline</span>
    <span>of things we can do to improve.</span>
    <span>And you're seeing some of those,</span>
    <span>you're seeing a lot of action</span>
    <span>in what's called retrieval augmented generation.</span>
    <span>And that's what you're seeing in the web search engines,</span>
    <span>but there's lots of other applications for that.</span>
    <span>There's an interface design part to this.</span>
    <span>So it's not just, so if we can condition models</span>
    <span>on things we can retrieve, like results from the web,</span>
    <span>but then we can also have the model site</span>
    <span>where its sources are to attribute things.</span>
    <span>And so you as a user can check and see if you trust.</span>
    <span>So there's those aspects and we can bring out sort of</span>
    <span>a general model, the model you might get</span>
    <span>if you first come to our API up to a certain level.</span>
    <span>Then if you have a particular application</span>
    <span>where you're much more sensitive to the quality,</span>
    <span>we can say, well, there's specific things we can do</span>
    <span>for that use case to make it better.</span>
    <span>And the gap between whatever performance you get</span>
    <span>from the API and sort of 100%,</span>
    <span>you can think of that as there's basically</span>
    <span>sort of an exponential effort curve.</span>
    <span>You'll never get to 100%,</span>
    <span>but you can keep pushing it more and more</span>
    <span>depending on how much effort.</span>
    <span>And that'll cost in terms of money,</span>
    <span>but there are those dimensions that we can push.</span>
    <span>So for a lot of use cases, I think what we have today</span>
    <span>will be enough with the right interfaces,</span>
    <span>the right deployment, and also training users</span>
    <span>to understand how to use these things</span>
    <span>and then what to trust and what not to trust.</span>
    <span>There are use cases that are still beyond us</span>
    <span>and I'd still caution anyone from deploying these models</span>
  </div>
  <div>
    <span>in safety-critical situations, yeah.</span>
    <span>Yeah, that's a great answer.</span>
    <span>And I just wanna underscore again,</span>
    <span>the point that you made that the state of the art</span>
    <span>in the world of research is far ahead</span>
    <span>of what's been deployed commercially.</span>
    <span>So what folks are seeing even with chat, GPT, and so forth,</span>
    <span>there's much more powerful technology</span>
    <span>that's already been developed,</span>
    <span>which I think is exciting.</span>
    <span>Exciting and a little scary for the world.</span>
    <span>One question I'm curious to hear all three of your thoughts</span>
    <span>on and Chris, we can start with you,</span>
    <span>is there's obviously, as we've talked about,</span>
    <span>a tremendous amount of interest in buzz</span>
    <span>around generative AI, a ton of capital flowing</span>
    <span>into the space, a ton of interest.</span>
    <span>But also I would say, I think it's fair to say</span>
    <span>that the signal to noise ratio in the world of AI</span>
    <span>has deteriorated over the past several months.</span>
    <span>There are a lot of folks that you might think of</span>
    <span>as tourists on the investing side,</span>
    <span>on the founding side, et cetera, flooding into the category.</span>
    <span>Do you worry that we may be entering</span>
    <span>some version of a bubble in AI,</span>
    <span>and is that something you're concerned about?</span>
    <span>Not really, I think the companies that will like,</span>
    <span>succeed at the companies that know how to build</span>
    <span>either research product or both.</span>
    <span>And I think what's great is a lot of people</span>
    <span>are finally paying attention to the space</span>
    <span>and how transformative models and multimodalities will be,</span>
    <span>and how useful they're gonna be.</span>
    <span>I remember showing a large ad agency in New York</span>
    <span>four years ago, an earlier version of a text to image model,</span>
    <span>and it was just really hard for everyone to understand</span>
    <span>the idea that you can generate images via language.</span>
    <span>It was really, really hard to understand the idea</span>
    <span>that these images are not coming from a database,</span>
    <span>or not being collage, or just being generated on real time.</span>
    <span>And I think we've improved a lot our research models,</span>
    <span>but also collectively, we've improved a lot</span>
    <span>our mental models around the technology,</span>
    <span>and that helps drive more interest into the space,</span>
    <span>because more people are interested in building finally</span>
    <span>like useful things.</span>
    <span>And a lot of the value will come still</span>
    <span>from the folks who understand how useful these models are.</span>
    <span>I think one common, I guess, misconception</span>
    <span>is to think about a model as a product,</span>
    <span>and that's perhaps what I see a lot of people get confused.</span>
    <span>They see a cool demo or a cool research,</span>
    <span>and I think it's important to understand</span>
    <span>that research is not product, and a demo is not business.</span>
    <span>But if you keep that in mind, I think it's just great</span>
    <span>that more minds are kind of thinking</span>
  </div>
  <div>
    <span>about the hard problems of the space at the same time.</span>
    <span>Yeah, what would you say, Phil?</span>
    <span>I mean, there's definitely froth,</span>
    <span>and there's sort of high quality companies</span>
    <span>and lower quality, but I wouldn't call it a bubble,</span>
    <span>so I think there's just demonstrable value there.</span>
    <span>We're seeing this, I mean, right at the top,</span>
    <span>you've got Google and Bing sort of fighting it out</span>
    <span>over big language models in search,</span>
    <span>and that obviously involves a huge amount</span>
    <span>of potential revenue, either loss,</span>
    <span>possibly on the Google side or gain.</span>
    <span>And just for Cohear, partly where Cohear came from</span>
    <span>for the founders, Aidan, Nick and Ivan,</span>
    <span>and also people like me who would work</span>
    <span>in these big tech companies, seen the research,</span>
    <span>that these models are already driving huge value</span>
    <span>within these companies, within Google,</span>
    <span>within Facebook, Transformers, other models</span>
    <span>that just permeate everything that's being done,</span>
    <span>but they haven't reached outside of those companies.</span>
    <span>It's very difficult for the average developer</span>
    <span>to get the same effect that a developer</span>
    <span>within one of these big tech companies can get.</span>
    <span>So I think that the values demonstrated,</span>
    <span>and it's there, it's a question of, again,</span>
    <span>how to go from the models, the research ideas</span>
    <span>into products, what are actually the,</span>
    <span>where's the product market fit,</span>
    <span>what are the actual sort of killer applications</span>
    <span>and ways of packaging these models up?</span>
    <span>Yep.</span>
    <span>Dave, what do you think?</span>
    <span>Is the AI space too overheated?</span>
    <span>I wish there were less copywriting tools popping up there,</span>
    <span>but no, I don't think so.</span>
    <span>And I was just thinking about, even like my day today,</span>
    <span>I answered some emails on the plane with Jasper,</span>
    <span>but outside of that, I'm not using this everywhere I go,</span>
    <span>and if you log off Twitter,</span>
    <span>you're not gonna just be bumping into it.</span>
    <span>It's not gonna be in a lot of the products that you're using.</span>
    <span>My parents are not using generative AI,</span>
    <span>and yet we see that it is really, really valuable.</span>
    <span>So there's a lot there, and you said the developers</span>
    <span>aren't kind of touching the value yet,</span>
    <span>and then even they're not building it</span>
    <span>for regular people out there.</span>
    <span>And so I think it is a rare situation</span>
    <span>where it's truly valuable.</span>
    <span>There's all this money that has flowed in recently.</span>
    <span>A lot of really great people are flowing into it.</span>
    <span>I think, yeah, people are gonna realize</span>
    <span>it is harder to build a real business.</span>
    <span>It's easy to get a lot of retweets</span>
    <span>and have a really cool curated demo,</span>
    <span>but like to get something out there</span>
    <span>into the world is much harder.</span>
    <span>But no, I think it's gonna be a really exciting few years</span>
    <span>where we see that, again,</span>
    <span>it's kind of what Web3 promised to be.</span>
    <span>We're just gonna see this really impact lives</span>
    <span>and really be a really beneficial thing for society.</span>
    <span>Yep, yep.</span>
    <span>Chris, I'm curious, especially given that the product</span>
    <span>that you all have built at Runaway</span>
    <span>is meant to put these really powerful AI tools</span>
    <span>into as many people's hands as possible,</span>
    <span>what advice would you have for folks in the audience</span>
    <span>who have heard about generative AI,</span>
    <span>have maybe played around with chat GPT,</span>
    <span>are excited about the potential of the technology</span>
    <span>and want to further explore,</span>
    <span>either for their company or for themselves personally,</span>
    <span>how they might be able to use the technology</span>
  </div>
  <div>
    <span>and add value in their lives.</span>
    <span>What kind of, what steps would you suggest to get started?</span>
    <span>I'm really looking forward, we're at a time</span>
    <span>where we're collectively gonna refer to these products,</span>
    <span>which is products and not AI products,</span>
    <span>in the same way that we don't refer to companies</span>
    <span>as internet companies,</span>
    <span>we're just like everyone uses the internet nowadays.</span>
    <span>And so the way we like to think about it</span>
    <span>is like just think about it as a fundamental piece</span>
    <span>of technology that will embed it in everything you do.</span>
    <span>It doesn't matter if you're a filmmaker</span>
    <span>or a journalist or a lawyer,</span>
    <span>it will be like a fundamental layer and an assistant</span>
    <span>and an enhancement and an augmentation</span>
    <span>to your existing workflows.</span>
    <span>You may become more productive,</span>
    <span>you're gonna become from the storytelling perspective,</span>
    <span>which is where we work with much more able</span>
    <span>to execute ideas faster and better at a fraction of the cost.</span>
    <span>I think embracing that this is something different.</span>
    <span>It's not, I think sometimes we try to hold these models</span>
    <span>to impossible standards</span>
    <span>to compare them to things we've used in the past,</span>
    <span>but I think this is just new.</span>
    <span>It's totally new, it needs to be,</span>
    <span>and that's why we go back to what I was saying before.</span>
    <span>It requires that team current exploration to discover</span>
    <span>and it's new like affordances.</span>
    <span>And I think that mentality of like exploring</span>
    <span>and discovering is just fundamental</span>
    <span>because it's gonna be everywhere.</span>
    <span>Yep.</span>
    <span>Phil, what would you say to that?</span>
    <span>To folks who have heard about the technology</span>
    <span>and are wondering how it can best impact their company?</span>
    <span>Well, the first thing is to play with it.</span>
    <span>There are these great APIs out there</span>
    <span>that you can just start playing with the models.</span>
    <span>That's a great thing to do</span>
    <span>because one, you can see the promise that they can do,</span>
    <span>but you also pretty quickly understand</span>
  </div>
  <div>
    <span>the rough edges and the limitations.</span>
    <span>You understand that it's not magic.</span>
    <span>There are ways of using these tools</span>
    <span>that give a good result and others that don't.</span>
    <span>The other thing I'd say for anyone</span>
    <span>sort of thinking about this in their business context</span>
    <span>is thinking about traditional AI,</span>
    <span>you sort of have to reverse your notion.</span>
    <span>So traditional AI really focused on high precision</span>
    <span>and low recall, low coverage.</span>
    <span>So we could do a few things really accurately</span>
    <span>and a lot of stuff it just wouldn't do.</span>
    <span>The models we're building now are very broad coverage.</span>
    <span>I'll try and do everything.</span>
    <span>ChatGPT will always give you an answer,</span>
    <span>whether it knows the answer or not,</span>
    <span>but the precision is low.</span>
    <span>So in terms of use cases, you have to think about,</span>
    <span>well, where does that fit?</span>
    <span>Where am I willing to have lower precision</span>
    <span>but broad coverage and robustness,</span>
    <span>which is very important for interacting with people</span>
    <span>because people always want an answer.</span>
    <span>They don't want the system to break and refuse to answer.</span>
    <span>So having that mindset,</span>
    <span>which does sort of reverse where you think about</span>
    <span>where to put these things.</span>
    <span>So definitely anything involving sort of recommendation,</span>
    <span>where there's not necessarily a right answer,</span>
    <span>where there's, where the model essentially helping you</span>
  </div>
  <div>
    <span>and creativity and all these sorts of things.</span>
    <span>That's where a lot of the strength for these models is.</span>
    <span>Yeah, yeah.</span>
    <span>We have just about one minute left.</span>
    <span>So last question.</span>
    <span>I'm curious here are the brief thoughts</span>
    <span>from each of the three of you.</span>
    <span>Dave will start with you.</span>
    <span>And this can be from your company or otherwise.</span>
    <span>What is one specific concrete use case</span>
    <span>or application of generative AI</span>
    <span>that maybe is not widely known or appreciated</span>
    <span>that you are really excited about</span>
    <span>that's adding value in the world?</span>
    <span>I think generative AI doing more stuff for you</span>
    <span>is happening some now,</span>
    <span>but also kind of right around the corner</span>
    <span>instead of just generating text or an image or a video,</span>
    <span>you'll be able to have it go and check your email</span>
    <span>and summarize all of it and send you one email back</span>
    <span>kind of all to summarize</span>
    <span>or be able to chain different products together</span>
    <span>and just like navigate the world with a simple interface</span>
    <span>where it's actually doing more,</span>
    <span>not just writing or generating images.</span>
    <span>Yep, at all.</span>
    <span>Yeah, in a similar sort of way,</span>
    <span>I think that particularly for language becoming the glue</span>
    <span>that glues a lot of things together,</span>
    <span>but the way we think of sort of what we're developing</span>
    <span>at Cohere in the end is the ability</span>
    <span>to allow these models to act in the world.</span>
    <span>So not just sort of have a discussion,</span>
    <span>but the model can interact with APIs,</span>
    <span>it can interact with web pages, fill in web forms,</span>
    <span>it can visualize data for you that's been retrieved</span>
    <span>and all these sorts of things.</span>
    <span>Again, this is something that most of these things</span>
    <span>have shown up in the research work,</span>
    <span>they've been demonstrated</span>
    <span>and now the challenge is to bring them</span>
    <span>into sort of commercial applications.</span>
    <span>Absolutely.</span>
    <span>Chris?</span>
    <span>I think storytelling and the way we tell stories,</span>
    <span>the way we make movies and filmmaking,</span>
    <span>it's gonna be forever changed</span>
    <span>and so really excited to be part of that change.</span>
    <span>Awesome.</span>
    <span>Thanks so much guys, amazing conversation,</span>
    <span>super excited what you guys are doing.</span>
    <span>Thank you.</span>
    <span>Thank you.</span>
    <span>Thank you.</span>
    <span>Thank you.</span>
    <span>Thank you.</span>
    <span>Thank you.</span>
  </div>
</html>
